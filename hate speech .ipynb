{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e65b004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\PUNEET\n",
      "[nltk_data]     SHEOKAND\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   0        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
      "                                                 tweet  \\\n",
      "0    !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1    !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2    !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3    !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4    !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "..                                                 ...   \n",
      "195  \"@Montrell_: I'm tired of bitches saying I loo...   \n",
      "196  \"@MotherJones: 10 birds your grandkids may nev...   \n",
      "197          \"@MvckFadden: \"Stay beautiful you bitch\"\"   \n",
      "198  \"@NICKIMINAJ: #WutKinda\\n\\nr purple. Ceeeleee\"...   \n",
      "199  \"@NastyCopper: Money getting taller and bitche...   \n",
      "\n",
      "                           labels  \n",
      "0    No Hate and Offensive Speech  \n",
      "1                Offensive Speech  \n",
      "2                Offensive Speech  \n",
      "3                Offensive Speech  \n",
      "4                Offensive Speech  \n",
      "..                            ...  \n",
      "195              Offensive Speech  \n",
      "196  No Hate and Offensive Speech  \n",
      "197              Offensive Speech  \n",
      "198              Offensive Speech  \n",
      "199              Offensive Speech  \n",
      "\n",
      "[200 rows x 2 columns]\n",
      "0.8783469861841301\n",
      "['No Hate and Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn. feature_extraction. text import CountVectorizer\n",
    "from sklearn. model_selection import train_test_split\n",
    "from sklearn. tree import DecisionTreeClassifier\n",
    "import nltk\n",
    "import re\n",
    "nltk. download('stopwords')\n",
    "from nltk. corpus import stopwords\n",
    "stopword=set(stopwords.words('english'))\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\PUNEET SHEOKAND\\\\OneDrive\\\\Desktop\\\\data.csv\")\n",
    "#To preview the data\n",
    "print(data. head())\n",
    "data[\"labels\"] = data[\"class\"]. map({0: \"Hate Speech\", 1: \"Offensive Speech\", 2: \"No Hate and Offensive Speech\"})\n",
    "data = data[[\"tweet\", \"labels\"]]\n",
    "print(data. head(200))\n",
    "def clean (text):\n",
    "    text = str (text). lower()\n",
    "    text = re. sub('[.?]', '', text)\n",
    "    text = re. sub('https?://\\S+|www.\\S+', '', text)\n",
    "    text = re. sub('<.?>+', '', text)\n",
    "    text = re. sub('[%s]' % re. escape(string.punctuation), '', text)\n",
    "    text = re. sub('\\n', '', text)\n",
    "    text = re. sub('\\w\\d\\w', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \". join(text)\n",
    "    text = [stemmer.stem(word) for word in text. split(' ')]\n",
    "    text=\" \". join(text)\n",
    "    return text\n",
    "data[\"tweet\"] = data[\"tweet\"]. apply(clean)\n",
    "x = np. array(data[\"tweet\"])\n",
    "y = np. array(data[\"labels\"])\n",
    "cv = CountVectorizer()\n",
    "X = cv. fit_transform(x)\n",
    "#Splitting the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "#Model building\n",
    "model = DecisionTreeClassifier()\n",
    "#Training the model\n",
    "model. fit(X_train,y_train)\n",
    "#Testing the model\n",
    "y_pred = model. predict (X_test)\n",
    "y_pred#Accuracy Score of our model\n",
    "from sklearn. metrics import accuracy_score\n",
    "print (accuracy_score (y_test,y_pred))\n",
    "#Predicting the outcome\n",
    "inp = \"You are too bad and I dont like your attitude\"\n",
    "inp = cv.transform([inp]).toarray()\n",
    "print(model.predict(inp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
